import numpy as np
import matplotlib.pyplot as plt
import math
import pickle
import scipy.special

import random

def uniform_prior(theta, theta_bounds):

   
    # Dimensions of the sampled parameter
    N, d = theta.shape
   
    # Area of the region
    A = np.prod(theta_bounds[:,1]-theta_bounds[:,0])
   
    # Determine what samples lie within region
    in_region = np.ones(N)
    for di in range(d):
        in_region *= (theta_bounds[di,0]<=theta[:,0])\
                    *(theta[:,1]<=theta_bounds[di,1])
                   
    # Multiply by Area
    prior = in_region/A
   
    return prior



def gauss_log_likelihood(y, sigma):

    # Data size
    N, m = y.shape
   
    # Gaussian log-likelihood
    ll = -0.5*m*np.log(2*np.pi) - 0.5*m*np.log(sigma**2) \
        - 0.5/(sigma**2)*np.sum(y**2,axis=1)
    
    return ll
def Metropolis_hasting(M,m,target_function,proposal_function ):#= 'Gaussian'):


    #Set empty parameters
    theta1 = []
    theta2 = []
    X_t = np.ones(2*m)
    
    #if proposal_function == 'Gaussian':
        #proposal_function = x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.1)

    for i in range(M):
        # Propose a new state from multivariate distribution 
        Y = proposal_function(X_t)
        Y1 = Y1 = Y[:m]
        Y2 = Y[m:]
        #calculate acceptance rate alpha ratio, reduction due to symmetric proposal distributions.
        r = target_function(Y)/target_function(X_t)
       # print('r=',r)
        
        alpha = np.minimum(1, r)
        #print('alpha=',alpha)
        
        if np.random.random() < alpha:
            X_t = Y
            theta1.append(Y1)
            theta2.append(Y2)
        else:
            
            theta1.append(X_t[:m])
            theta2.append(X_t[m:])
    theta1 = np.array([arr.flatten() for arr in theta1])
    theta2 = np.array([arr.flatten() for arr in theta2])
    #print(theta2)
    return theta1, theta2
    
    
def Umbrella_sampling (NS,data, sigma ,target_function, proposal_function ):   

        
    # Data size
    N, m = y.shape 
    
    #extrac data
    y1 = data['model01']['y']
    y2 = data['model02']['y']
    tht2 = data['model02']['tht']
    
    
    # Data size
    N, m = tht2.shape
   
    
    #Sampling using mertropolis hasting MCMC method.
    tht1,tht2  = Metropolis_hasting(N,m,target_function,proposal_function)

    #tht2 = Metropolis_hasting(N,m,target_function,proposal_function)
    theta_bounds = np.array([[0.7,1.3],[0.7,1.3]])
    print('tht2=', tht2.shape)
    
    
    #Finding Z1
    prior1 = uniform_prior(tht1, theta_bounds)
    likelihood1 = gauss_log_likelihood(y1,sigma)
    q11 = prior1*likelihood1
    
    #Finding Z2
    prior2 = uniform_prior(tht2, theta_bounds)
    likelihood2 = gauss_log_likelihood(y2,sigma)
    q22 = prior2*likelihood2
    
    #Let q12 and q21 = q3, there for the sum of each denominator become N and cancles.
    rh1 = np.sum(q11/q22)
        
    #Update q3
    q3 =  q11 - rh1 * q22
        
    return q3 

if __name__ == '__main__':
    atomic_data_pickle_path = 'C:\\Users\\whisk\\atomic_data.pickle'
    #atomic_data_path =  '../data/atomic_data.pickle'
    with open('atomic_data.pickle', 'rb')  as f:
       data = pickle.load(f)
    NS = 2   
    sigma = 0.1
    #HMModel_compaire (data,sigma)
    #RisModel_compaire (data,sigma)
   
    tht2 = data['model02']['tht']

    y = data['model01']['y']
    

    
    target_function = lambda x : scipy.stats.multivariate_normal.logpdf(x, cov=np.eye(len(x)) * 0.1)
    
    proposal_function  = lambda x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.1)
    
    #print(y.shape)
    US = Umbrella_sampling (NS,data, sigma ,target_function, proposal_function   )
