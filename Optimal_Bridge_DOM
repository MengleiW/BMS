def Metropolis_hasting(M,m,target_function,proposal_function ):
    """
    Metropolis-Hasting algorithm for sampling from a target distribution.

    Parameters:
    - M: Number of samples to generate.
    - m: The dimension of the parameter space.
    - target_function: Function to compute the log-likelihood of a state.
    - proposal_function: Function to propose a new state given the current state.

    Returns:
    - A list of sampled states from the target distribution.
       
     Modified:
   
         11/09/2023 (Menglei Wang)
    """ 

    #Set empty parameters
    theta = []
    
    X_t = np.zeres(m)
    
    #if proposal_function == 'Gaussian':
        #proposal_function = x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.1)

    for i in range(M):
        # Propose a new state from multivariate distribution 
        Y = proposal_function(X_t)
        
        #calculate acceptance rate alpha ratio, reduction due to symmetric proposal distributions.
        r = target_function(Y)/target_function(X_t) #* weights
       # print('r=',r)
        
        alpha = np.minimum(1, r)
        #print('alpha=',alpha)yh
        
        if np.random.random() < alpha:
            X_t = Y
            
        theta.append(X_t)
        theta= np.array(theta)
    return theta

def target_function(method,gammas,initial_conditions,T, k, observed_y, observed_yp, sigma_y, sigma_yp):
    """
    Simulates and saves data for a range of parameter values over specified time points using a numerical method.

    Inputs:
        method: Function, the numerical method used for simulating the model (e.g., Euler forward or trapezoidal).
        gammas: Array, range of parameter values (e.g., damping coefficients) to be tested.
        initial_conditions: Array, initial state of the system (usually includes initial position and velocity).
        T: Array, time points for which the data is to be simulated.
        k: Float, a parameter of the system (e.g., stiffness coefficient in a damped oscillator model).
        
        observed_y: Array, observed data for position (y).
        observed_yp: Array, observed data for velocity (y').
        sigma_y: Standard deviation of error in position measurements.
        sigma_yp: Standard deviation of error in velocity measurements.
        
        
    Outputs:
        target_function:  where each element contains the simulated system states for each value of gamma at given time point.
    """
    simulated_data = np.zeros((len(T),2))
    simulated_data[0,:] = initial_conditions
    
    for i, t in enumerate(T[1:], start=1): 
        h = t - T[i - 1]
        simulated_data [i,:] = method(gammas, k, simulated_data[i - 1,:], t, h)
        
    ll = calculate_combined_log_likelihood(simulated_data, observed_y, observed_yp, sigma_y, sigma_yp)
    target_function = np.sum(ll)
    return  target_function


def OptimalBridge (method,initial_conditions,T, k, data,N,N1,N2, check_points,gammas, observed_y, observed_yp, sigma_y, sigma_yp,Timepoint_of_interest):
    
    """
    Optimal Bridge Sampling uses Metropolis-Hasting aproximate Z and iteratively updates the aproximation.

    Inputs:
        method: Function, the numerical method used for simulating the model (e.g., Euler forward or trapezoidal).
        gammas: Array, range of parameter values (e.g., damping coefficients) to be tested.
        initial_conditions: Array, initial state of the system (usually includes initial position and velocity).
        T: Array, time points for which the data is to be simulated.
        k: Float, a parameter of the system (e.g., stiffness coefficient in a damped oscillator model).
        h: Float, time step.
        observed_y: Array, observed data for position (y).
        observed_yp: Array, observed data for velocity (y').
        sigma_y: Standard deviation of error in position measurements.
        sigma_yp: Standard deviation of error in velocity measurements.
       
    Outputs:
   
         Rhat: (0,0) The ratio between Z1 and Z2

       
       
     Modified:
   
         10/07/2023 (Menglei Wang)
           
    """
    Z = []
    Zhat = Slove_Z(data,check_points,gammas, observed_y, observed_yp, sigma_y, sigma_yp)[Timepoint_of_interest]
    
    
    target_function_Post =  target_function(method, gammas,initial_conditions,T, k, observed_y, observed_yp, sigma_y, sigma_yp)/number_of_gammas
    proposal_function_Post  = lambda x: np.random.multivariate_normal(x, cov=np.eye(len(x)) *0.3)
    target_function_phat = lambda x : scipy.stats.multivariate_normal.logpdf(x, cov=np.eye(len(x)) * 0.3)
    proposal_function_phat  = lambda x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.3)
    for i in range (N-1):
         #Taking sampling using Metropolis Hasting algrithm. 
         tht2 = Metropolis_hasting(N,target_function_Post,proposal_function_Post )
         tht1 = Metropolis_hasting(N,target_function_phat,proposal_function_phat )
         
         
         #Finding Q11
         q11 =  target_function(method,tht1,initial_conditions,T, k, observed_y, observed_yp, sigma_y, sigma_yp)#[]
         #print('l1=',likelihood1)
         
         
         #Finding Q12
         q12 = target_function(method,tht2, initial_conditions,T, k, observed_y, observed_yp, sigma_y, sigma_yp)
         #print('q12=',q12)
         
         #Finding Q21
         q21 = scipy.stats.multivariate_normal.logpdf(tht1, cov=np.eye(len(tht1)) * 0.3)
         #print('q21=',q21)
        
         #Finding Q22
        
         q22 = scipy.stats.multivariate_normal.logpdf(tht2, cov=np.eye(len(tht2)) * 0.3)
         #print('l2=',likelihood2)
        
         #epsilon = 1e-10
         #q11 = np.maximum(q11, epsilon)
         #q12 = np.maximum(q12, epsilon)
         #q21 = np.maximum(q21, epsilon)
         #q22 = np.maximum(q22, epsilon)
         
         
         Q1 = np.logaddexp.reduce(np.log(q11)) - np.logaddexp.reduce(np.log(N1*q11 + N2*Zhat*q21))+N1
         Q2 = np.logaddexp.reduce(np.log(q22)) - np.logaddexp.reduce(np.log(N1*q12 + N2*Zhat*q22))+N2
         print('Q1=',Q1)
         print('Q2=',Q2)
         
         
         
         
         
         zhat = np.exp(Q1 - Q2)
         Z.append(zhat*Z)

    return Z
