def Metropolis_hasting(weights,M,m,target_function,proposal_function ):
    """
    Description: Use the Metropolis-Hastings sampler to generate a sample from a Rayleigh distribution.

    Inputs:
       
        sigma: double >0, the standard deviation of Multivariate normal
               distribution representing the experimental error.
       
        m: the dimension of the variables.
        
        M: number of samples 
        
        Target_function:   Fucntion of distribution that we wish to sample from. 
        
        proposal_function: Function that we propose for candidates.
        
       
    Outputs:
   
         Theta1: Sample gathered from the target distribution.
         Theta2: Sample gathers from the target distribution.
       
       
     Modified:
   
         11/09/2023 (Menglei Wang)
    """ 

    #Set empty parameters
    theta = []
    
    X_t = np.ones(m)
    
    #if proposal_function == 'Gaussian':
        #proposal_function = x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.1)

    for i in range(M):
        # Propose a new state from multivariate distribution 
        Y = proposal_function(X_t)
        
        #calculate acceptance rate alpha ratio, reduction due to symmetric proposal distributions.
        r = target_function(Y)/target_function(X_t) #* weights
       # print('r=',r)
        
        alpha = np.minimum(1, r)
        #print('alpha=',alpha)yh
        
        if np.random.random() < alpha:
            X_t = Y
            
        theta.append(X_t)
        theta= np.array(theta)
    return theta

def target_function(method,gammas, k, y, t, h, observed_y, observed_yp, sigma_y, sigma_yp):
    """
    Simulates and saves data for a range of parameter values over specified time points using a numerical method.

    Inputs:
        method: Function, the numerical method used for simulating the model (e.g., Euler forward or trapezoidal).
        gammas: Array, range of parameter values (e.g., damping coefficients) to be tested.
        initial_conditions: Array, initial state of the system (usually includes initial position and velocity).
        T: Array, time points for which the data is to be simulated.
        k: Float, a parameter of the system (e.g., stiffness coefficient in a damped oscillator model).
        h: Float, time step.
        observed_y: Array, observed data for position (y).
        observed_yp: Array, observed data for velocity (y').
        sigma_y: Standard deviation of error in position measurements.
        sigma_yp: Standard deviation of error in velocity measurements.
        
        
    Outputs:
        target_function:  where each element contains the simulated system states for each value of gamma at given time point.
    """
    simulated_data = method(gammas, k, y, t, h)
    ll = calculate_combined_log_likelihood(simulated_data, observed_y, observed_yp, sigma_y, sigma_yp)
    target_function = np.sum(ll)
    return  target_function


def OptimalBridge (method,k, y, t, h, data,N,N1,N2, check_points,gammas, observed_y, observed_yp, sigma_y, sigma_yp,Timepoint_of_interest):
    
    """
    Description: To find the uniform prior.

    Inputs:
       
        Ns:   (1,1) number of stages
        
        data: (2,2) The data generated by a MCMC = {'model01': {'tht': tht_for_model01, 'y': y_vals_for_model01 }, 
              'model02': {'tht': tht_for_model02, 'y': y_vals_for_model02 }} 
       
        sigma: double >0, the standard diviation of Multivariate normal
               distribution representing the experimental error.
       
    Outputs:
   
         Rhat: (0,0) The ratio between Z1 and Z2

       
       
     Modified:
   
         10/07/2023 (Menglei Wang)
           
    """
    Z = []
    Zhat = Slove_Z(data,check_points,gammas, observed_y, observed_yp, sigma_y, sigma_yp)[Timepoint_of_interest]
    
    
    target_function_Post =  target_function(gammas, k, y, t, h, observed_y, observed_yp, sigma_y, sigma_yp)/number_of_gammas
    proposal_function_Post  = lambda x: np.random.multivariate_normal(x, cov=np.eye(len(x)) *0.3)
    target_function_phat = lambda x : scipy.stats.multivariate_normal.logpdf(x, cov=np.eye(len(x)) * 0.3)
    proposal_function_phat  = lambda x: np.random.multivariate_normal(x, cov=np.eye(len(x)) * 0.3)
    for i in range (N-1):
         #Taking sampling using Metropolis Hasting algrithm. 
         tht2 = Metropolis_hasting(N,target_function_Post,proposal_function_Post )
         tht1 = Metropolis_hasting(N,target_function_phat,proposal_function_phat )
         
         
         #Finding Q11
         q11 =  target_function(method,tht1, k, y, t, h, observed_y, observed_yp, sigma_y, sigma_yp)#[]
         #print('l1=',likelihood1)
         
         
         #Finding Q12
         q12 = target_function(method,tht2, k, y, t, h, observed_y, observed_yp, sigma_y, sigma_yp)
         #print('q12=',q12)
         
         #Finding Q21
         q21 = scipy.stats.multivariate_normal.logpdf(tht1, cov=np.eye(len(tht1)) * 0.3)
         #print('q21=',q21)
        
         #Finding Q22
        
         q22 = scipy.stats.multivariate_normal.logpdf(tht2, cov=np.eye(len(tht2)) * 0.3)
         #print('l2=',likelihood2)
        
         #epsilon = 1e-10
         #q11 = np.maximum(q11, epsilon)
         #q12 = np.maximum(q12, epsilon)
         #q21 = np.maximum(q21, epsilon)
         #q22 = np.maximum(q22, epsilon)
         
         
         Q1 = np.logaddexp.reduce(np.log(q11)) - np.logaddexp.reduce(np.log(N1*q11 + N2*Zhat*q21))+N1
         Q2 = np.logaddexp.reduce(np.log(q22)) - np.logaddexp.reduce(np.log(N1*q12 + N2*Zhat*q22))+N2
         print('Q1=',Q1)
         print('Q2=',Q2)
         
         
         
         
         
         zhat = np.exp(Q1 - Q2)
         Z.append(zhat*Z)

    return Z
