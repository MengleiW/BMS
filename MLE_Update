import numpy as np
import scipy
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import torch
from scipy.misc import derivative
import numdifftools as nd

from scipy.integrate import quadrature

def damped_oscillator(t, y, gamma, k):
    """
    Models a damped oscillator system.

    Inputs:
          t: Float, the current time point.
          y: List, current state of the system.
          gamma: Float, damping coefficient.
          k: Float, stiffness coefficient.

    Outputs:
         [y[1], f_t - gamma*y[1] - k*y[0]]: List, Derivative of the system state.
    """
    f_t = 0  
    #f_t = np.sin(t) 
    gamma = gamma if isinstance(gamma, float) else gamma[0]
    #print("gamma=",[y[1], f_t - gamma*y[1] - k*y[0]])
    return [y[1], f_t - gamma*y[1] - k*y[0]]

def simulate_observed_data(gamma, k, initial_conditions, ts, N, noise_level_s, noise_level_j):
    """
    Simulates the damped oscillator system over a given time span using solve_ivp.

    Inputs:
      gamma: Float, damping coefficient.
      k: Float, stiffness coefficient.
      initial_conditions: List, initial state of the system.
      ts: List, time span for simulation .
      N: Integer, number of points to evaluate in the time span.
      smooth_noise_level: number, level of random noise in the first half (smooth phase).
      jumpy_noise_level: number, level of random noise in the second half (jumpy phase).
    Outputs:
      (y, yp): list, where y is the position array and yp is the velocity array over the time span.
    """
    
    sol = scipy.integrate.solve_ivp(damped_oscillator, ts, initial_conditions, args=(gamma, k), t_eval=T)
    
    y = sol.y[0]
    yp = sol.y[1]
    #print("y1=",y)
    half = N // 2
    # Apply smooth noise to the first half and jumpy noise to the second half
    noise1 = np.concatenate([np.random.normal(0, noise_level_s,  half),
                             np.random.normal(0, noise_level_j, N -  half)])
    
    noise2 = np.concatenate([np.random.normal(0, noise_level_s,  half),
                             np.random.normal(0, noise_level_j, N -  half)])
    y += noise1
    #print("noise1=",noise1)
    yp += noise2
    #print("y2=",y)
    return y, yp

def euler_forward(gamma, k, y0, t, h):
    """
    Numerically approximates the solution of the damped oscillator using the Euler forward method for a single time point.

    Inputs:
      gamma: Array, range of damping coefficients.
      k: Float, stiffness coefficient.
      y0: 2D Array, initial states of the system for each gamma (position and velocity).
      t: Float, current time.
      h: Float,times step length.

    Outputs:
      y: 2D Array, where each row corresponds to the system states (position and velocity) for a specific gamma.
    """

    y_t_plus_one = y0 + h * np.array(damped_oscillator(t, y0, gamma, k))
    #print(f"Euler Method: gamma={h}, y0={damped_oscillator(t, y0, gamma, k)}, y_t_plus_one={y_t_plus_one}") 
    return y_t_plus_one

def trapezoidal_method(gamma, k, y0, t, h ):
    """
    Numerically approximates the solution of the damped oscillator using the trapezoidal method for a single time point.

    Inputs:
      gammas: Array, range of damping coefficients.
      k: Float, stiffness coefficient.
      initial_conditions: 2D Array, initial states of the system for each gamma (position and velocity).
      t: Float, current time.
      h: Float,times step length.

    Outputs:
      y: 2D Array, where each row corresponds to the system states (position and velocity) for a specific gamma.
    """
    f_n = np.array(damped_oscillator(t, y0, gamma, k))
    y_pred = y0 + h * f_n
    f_n_plus_1 = np.array(damped_oscillator(t + h, y_pred, gamma, k))
    y_t_puls_one = y0 + h / 2 * (f_n + f_n_plus_1)
    return y_t_puls_one

def euler_forward_z(gamma, k, y0, tao):
    """
    Numerically approximates the solution of the damped oscillator using the Euler forward method for a single time point.

    Inputs:
      gammas: Array, range of damping coefficients.
      k: Float, stiffness coefficient.
      y0: 2D Array, initial states of the system for each gamma (position and velocity).
      T: Float, Time point.
      

    Outputs:
      y: 2D Array, where each row corresponds to the system states (position and velocity) for a specific gamma.
    """

    y = np.zeros((len(tao), 2))
    y[0, :] = y0
    
    if len(tao)>1:
        for i, t in enumerate(tao[:-1]):
            h = tao[i+1] - tao[i]
            y[i + 1, :] = y[i, :] + h * np.array(damped_oscillator(t, y[i, :], gamma, k))
            
    return y

def trapezoidal_method_z(gamma, k, y0, tao):
    """
    Numerically approximates the solution of the damped oscillator using the trapezoidal method for a single time point.

    Inputs:
      gammas: Array, range of damping coefficients.
      k: Float, stiffness coefficient.
      initial_conditions: 2D Array, initial states of the system for each gamma (position and velocity).
      T: Float, Time points.
      

    Outputs:
      y: 2D Array, where each row corresponds to the system states (position and velocity) for a specific gamma.
    """
    y = np.zeros((len(tao), 2))
    y[0, :] = y0
    if len(tao)>1:
        for i, t in enumerate(tao[:-1]):
            h = tao[i+1] - tao[i]
            f_n = np.array(damped_oscillator(t, y[i, :], gamma, k))
            y_pred = y[i, :] + h * f_n
            f_n_plus_1 = np.array(damped_oscillator(t + h, y_pred, gamma, k))
            y[i + 1, :] = y[i, :] + h / 2 * (f_n + f_n_plus_1)

    return y

def log_likelihood(simulated, observed_y,observed_yp,  noise_level):
    """
    Computes the combined log-likelihood of the observed position data for a given simulated dataset.
  
    Inputs:
        simulated: Array, the simulated data from the model.
        observed_y: Array, observed data for position (y).
        observed_yp: Array, observed data for velocity (y').
        noise_level: Float, standard deviation of noise for the data.


    Outputs:
        log_likelihood: Float, the combined log-likelihood value of the observed data given the simulated model outputs.

    """
    
    residuals_y = observed_y - simulated[0]  
    residuals_yp = observed_yp - simulated[1]  
    
    #print("residuals_yp=", residuals_yp)
    #print("observed_y=", observed_y) 
    #print(" simulated[0]=",  simulated)
    ll_y = -0.5 * np.log(2 * np.pi) - 0.5 * np.log(noise_level ** 2) - 0.5 / (noise_level ** 2) * (residuals_y ** 2)
    ll_yp = -0.5 * np.log(2 * np.pi) - 0.5 * np.log(noise_level ** 2) - 0.5 / (noise_level ** 2) * (residuals_yp ** 2)
    #print("Log-likelihood", ll_y + ll_yp)  
    return ll_y + ll_yp

def calculate_combined_log_likelihood(simulated, observed_y, observed_yp, noise_level_s, noise_level_j):
    """
    Computes the combined log-likelihood of the observed position and velocity data for a given simulated dataset.
    And since we are intrest both
    Inputs:
        simulated: Array, the simulated data from the model.
        observed_y: Array, observed data for position (y).
        observed_yp: Array, observed data for velocity (y').
        noise_level_s: Float, standard deviation of noise for the first half of the data.
        noise_level_j: Float, standard deviation of noise for the second half of the data.

    Outputs:
        log_likelihood: Float, the combined log-likelihood value of the observed data given the simulated model outputs.

    """
    ll_y = np.zeros(simulated.shape[0])
    ll_yp = np.zeros(simulated.shape[0])
    half = N // 2 
    #for i in range(simulated.shape[0]):
    
    
    for i in range(len(simulated)):
        if i < half:
            noise_level = noise_level_s
        else:
            noise_level = noise_level_j
        #print("residuals=", simulated)
        residuals_y = observed_y[i] - simulated[:, 0]
        residuals_yp = observed_yp[i] - simulated[:,1]
        ll_y[i] =  -0.5 * m * np.log(2 * np.pi) - 0.5 * m * np.log(noise_level**2) \
                - 0.5 / (noise_level**2) * np.sum(residuals_y**2)
        ll_yp[i] = -0.5 * m * np.log(2 * np.pi) - 0.5 * m * np.log(noise_level**2) \
                - 0.5 / (noise_level**2) * np.sum(residuals_yp**2)
        
        #ll_yp = np.sum(scipy.stats.norm.logpdf(residuals_yp, scale=sigma_yp))
    #ll_y = ll_y1 np.concatenate([ll_y1, ll_y2])
    ll = np.sum(ll_y) + np.sum(ll_yp)
    #print("ll=",ll)
    return ll


def gradient_log_likelihood_euler(gamma, observed_y,observed_yp, noise_level, k, y0,t, h):
    """
    Computes the gradient of the log-likelihood with respect to the damping coefficient gamma using the Euler forward method.

    Inputs:
        observed_y: Array of observed position data.
        gamma: Float, the current value of the damping coefficient.
        k: Float, stiffness coefficient.
        y0: List, initial conditions of the system.
        t: Float, current time.
        h: Float,times step length.
        noise_level: Float, standard deviation of noise for the data.
        
        Z_t: Normalizing constant.

    Outputs:
        grad_ll: Float, the gradient of the log-likelihood with respect to gamma.
    """
    y = euler_forward(gamma, k, y0, t, h)
    #grad_ll = np.gradient(y, gamma)
    ll_gamma = log_likelihood(y, observed_y,observed_yp, noise_level)
    y_plus_h = euler_forward(gamma + h, k, y0, t, h)
    ll_gamma_h = log_likelihood(y_plus_h, observed_y,observed_yp, noise_level)
    grad_ll = (ll_gamma_h - ll_gamma) / h
    
    return grad_ll




def gradient_log_likelihood_trapezoidal(gamma, observed_y,observed_yp, noise_level, k, y0, t, h):
    """
   Computes the gradient of the log-likelihood with respect to the damping coefficient gamma using the trapezoidal method.

   Inputs:
       observed_y: Array of observed position data.
       gamma: Float, the current value of the damping coefficient.
       k: Float, stiffness coefficient.
       y0: List, initial conditions of the system.
       t: Float, current time.
       h: Float,times step length.
       noise_level: Float, standard deviation of noise for the data.
       Z_t: Normalizing constant.

   Outputs:
       grad_ll: Float, the gradient of the log-likelihood with respect to gamma.
   """
    
    y = trapezoidal_method(gamma, k, y0, t, h)
    
    ll_gamma = log_likelihood(y, observed_y,observed_yp, noise_level)
    y_plus_h = trapezoidal_method(gamma + h, k, y0, t, h)
    ll_gamma_h = log_likelihood(y_plus_h, observed_y,observed_yp, noise_level)
    grad_ll = (ll_gamma_h - ll_gamma) / h
    return grad_ll










def optimize_gamma(log_likelihood, grad_log_likelihood, gamma_init, observed_y, observed_yp,noise_level, k, y0, t, h, method):
    
    result = scipy.optimize.minimize(
        fun=lambda gamma: -log_likelihood(method(gamma, k, y0, t, h), observed_y,observed_yp, noise_level),
        x0=gamma_init,
        jac=lambda gamma: -grad_log_likelihood(gamma, observed_y, observed_yp,noise_level, k, y0, t, h),
        bounds=[(0, 1)],
        method='L-BFGS-B'
    )
    #print(f"Optimization result: {result}")  # Debugging statement
    
    return result.x

    
    




def fisher_information(log_likelihood, gamma, observed_y,observed_yp, noise_level, k, y0, t, h, method):
    """
    Calculates the Fisher information using numerical differentiation.

    Inputs:
        log_likelihood: Function to compute the log-likelihood.
        gamma: Float, the current value of the damping coefficient.
        observed_y: Array of observed position data.
        noise_level: Float, standard deviation of noise for the data.
        k: Float, stiffness coefficient.
        y0: List, initial conditions of the system.
        t: Float, current time.
        h: Float, time step length.
        method: Numerical method for simulation (e.g., euler_forward or trapezoidal_method).

    Outputs:
        fisher_info: Float, the Fisher information value.
    """
    
    
    epsilon = 0.00001
    ll_gamma = log_likelihood(method(gamma, k, y0, t, h), observed_y,observed_yp, noise_level)
    #print("ll_gamma =",ll_gamma)
    
    
    if np.isclose(gamma, 0):
        ll_gamma_plus_epsilon = log_likelihood(method(gamma + epsilon, k, y0, t, h), observed_y, observed_yp, noise_level)
        gradient = (ll_gamma_plus_epsilon - ll_gamma) / epsilon
        second_derivative = (ll_gamma_plus_epsilon - 2 * ll_gamma + ll_gamma) / (epsilon ** 2)
    elif np.isclose(gamma, 1):
        ll_gamma_minus_epsilon = log_likelihood(method(gamma - epsilon, k, y0, t, h), observed_y, observed_yp, noise_level)
        gradient = (ll_gamma - ll_gamma_minus_epsilon) / epsilon
        second_derivative = (ll_gamma - 2 * ll_gamma + ll_gamma_minus_epsilon) / (epsilon ** 2)
    else:
        ll_gamma_plus_epsilon = log_likelihood(method(gamma + epsilon, k, y0, t, h), observed_y, observed_yp, noise_level)
        ll_gamma_minus_epsilon = log_likelihood(method(gamma - epsilon, k, y0, t, h), observed_y, observed_yp, noise_level)
        gradient = (ll_gamma_plus_epsilon - ll_gamma_minus_epsilon) / (2 * epsilon)
        second_derivative = (ll_gamma_plus_epsilon - 2 * ll_gamma + ll_gamma_minus_epsilon) / (epsilon ** 2)
        
    if np.isclose(gamma, 0) or np.isclose(gamma, 1):
        fisher = -(second_derivative + 2 * gradient)  # Adjusted Fisher Information including the gradient
    else:
        fisher = -second_derivative
    #print("fisher-",fisher)
    return fisher


    

def find_POST_t(gamma_init, observed_y,observed_yp, noise_level, N, k, y0, T, tol, eta_init, c1, c2, M=2):
    """
   Calculates the normalizing constant Z_t(M) after finding the MLE gamma.

   Inputs:
       gamma_init: Float, initial guess for gamma.
       observed_y: Array of observed position data.
       noise_level: Float, standard deviation of noise for the data.
       N: Integer, number of time points.
       k: Float, stiffness coefficient.
       y0: List, initial conditions of the system.
       T: Array, time points for the simulation.
       tol: Float, tolerance for convergence.
       eta_init: Float, initial step size.
       c1: Float, Armijo condition constant.
       c2: Float, curvature condition constant.
       M: Integer, number of methods (default is 2).

   Outputs:
       P_e: Float, the updated normalizing constant for Euler method.
       P_t: Float, the updated normalizing constant for trapezoidal method.
   """
    Z_e = [0.5]
    Z_t = [0.5]
    MLE_e = gamma_init
    MLE_t = gamma_init
    P_e = [0.5]
    P_t = [0.5]
    Z_E =[0.5]
    Z_T = [0.5]
    number_of_gammas = 10
   
    
    
    
    
    for t in range(1, len(T)):
        #print("len(T)=",len(T))
        #print("time step=",t)
        h = T[t] - T[t - 1]
        tao = T[:t]
        observed_y_t = observed_y[t]
        observed_yp_t = observed_yp[t]
        
        y0 = [observed_y[t - 1], observed_yp[t - 1]] 
        #print("y00=",y0)        
        MLE_e = optimize_gamma(log_likelihood, gradient_log_likelihood_euler, P_e[-1], observed_y_t,observed_yp_t, noise_level, k, y0, T[t - 1], h, euler_forward)
        MLE_t = optimize_gamma(log_likelihood, gradient_log_likelihood_trapezoidal, P_t[-1], observed_y_t,observed_yp_t, noise_level, k, y0, T[t - 1], h, trapezoidal_method)
        #print("MLE_e = ", MLE_e)
        #print("MLE_t = ", MLE_t)
        
       

        one_over_neg_fisher_e = fisher_information(log_likelihood, MLE_e, observed_y_t,observed_yp_t, noise_level, k, y0, T[t - 1], h, euler_forward)
        one_over_neg_fisher_t = fisher_information(log_likelihood, MLE_t, observed_y_t,observed_yp_t, noise_level, k, y0, T[t - 1], h, trapezoidal_method)
        #print("one_over_neg_Fisher_e = ", one_over_neg_fisher_e)
        #print("one_over_neg_Fisher_t = ", one_over_neg_fisher_t)
        if np.any(one_over_neg_fisher_e <= 0) or np.any(one_over_neg_fisher_t <= 0):
            break
        posterior_e = scipy.stats.norm(loc=MLE_e, scale=np.sqrt(1 / one_over_neg_fisher_e))
        posterior_t = scipy.stats.norm(loc=MLE_t, scale=np.sqrt(1 / one_over_neg_fisher_t))
        #print("posterior_e=", posterior_e)
        #print("posterior_t = ", posterior_t)
        
        model_prior_e = (P_e[-1])
        model_prior_t = (P_t[-1])
        
        

        likelihood_e = np.exp(log_likelihood(euler_forward(MLE_e, k, y0, T[t - 1], h), observed_y_t,observed_yp_t, noise_level))
        likelihood_t = np.exp(log_likelihood(trapezoidal_method(MLE_t, k, y0, T[t - 1], h), observed_y_t, observed_yp_t,noise_level))

        #print("likelihood_e = ", likelihood_e)
        #print("likelihood_t = ", likelihood_t)
        if np.any(np.isnan(likelihood_e)) or np.any(np.isnan(likelihood_t)):
            print("NaN in likelihoods")
            break

        Z_e.append(((likelihood_e * 1 / number_of_gammas) / posterior_e.pdf(MLE_e))[0])
        Z_t.append(((likelihood_t * 1 / number_of_gammas) / posterior_t.pdf(MLE_t))[0])
        #print("Z_e=",Z_e)
        #print("Z_t=",Z_t)
        if np.any(np.isnan(Z_e[-1])) or np.any(np.isnan(Z_t[-1])):
            #print("NaN in Z_t or Z_e")
            break

        P_e.append(model_prior_e * Z_e[-1] / (model_prior_e * Z_e[-1] + model_prior_t * Z_t[-1]))
        P_t.append(model_prior_t * Z_t[-1] / (model_prior_e * Z_e[-1] + model_prior_t * Z_t[-1]))
        #print("p_e = ",P_e)
        
        
        Z_E_bayesian_euler = compute_Z_quadrature(observed_y[:t], observed_yp[:t],noise_level, k, y0, T[:t ], h, euler_forward_z)
        Z_E_bayesian_trapezoidal = compute_Z_quadrature(observed_y[:t],observed_yp[:t], noise_level, k, y0, T[:t ], h,  trapezoidal_method_z)
        Z_E.append(Z_E_bayesian_euler)
        Z_T.append(Z_E_bayesian_trapezoidal)
    #print("Z_E=",Z_E)
    return P_e, P_t ,Z_E,Z_T,Z_e,Z_t

  

def compute_Z_quadrature(observed_y_t, observed_yp_t,noise_level, k, y0, t, tao, method):
    """
    Calculate the normalization constant Z using quadrature integration.

    Inputs:
        observed_y_t: Array, observed data for position (y) at time t.
        noise_level: Float, standard deviation of noise for the data.
        k: Float, stiffness coefficient.
        y0: List, initial conditions of the system.
        t: Float, current time.
        h: Float, time step length.
        method: Numerical method for simulation (e.g., euler_forward or trapezoidal_method).

    Outputs:
        Z: Float, the computed normalization constant using quadrature integration.
    """
    noise_level_s = 0.1
    noise_level_j = 0.3
    
    integrand = lambda gamma: np.exp(calculate_combined_log_likelihood(method(gamma, k, y0, t), observed_y, observed_yp, noise_level_s, noise_level_j))
    
    Z, _ = quadrature(integrand, 0, 1)
    return Z








if __name__ == '__main__':   
    
    #print('debug=',combined_log_likelihood)
    # Parameters 
    m = 1
    k = 0.5
    initial_conditions = [1, 0]
    number_of_gammas = 10
    Dimention_of_parameter_space = 1
    gammas = np.linspace(0, 1, number_of_gammas)
    
    N = 200
    
    T = np.linspace(0, 10, N)
    check_points = [1,5,8]
    
    Timepoint_of_interest=0
    Z_initial = 1
    N1 = 10
    N2 = 10
    sigma = 0.1
    #sigma_yp = 0.1
    noise_level_s = 0.1
    noise_level_j = 0.3
    noise_level = 0.4
    c1=1e-4
    c2=0.9
    eta_init=1
    tol=1e-6
    maga = 0.3
    gamma_init = 0.5
    gamma_true = 0.3
    
    
    
    observed_y, observed_yp = simulate_observed_data(gamma_true, k, initial_conditions, (T[0], T[-1]), N, noise_level_s, noise_level_j)
    
    
    #for t in range(1, len(T)):
        #log_likelihood_values = [] 
       # h = T[t] - T[t - 1]
       #observed_y_t = observed_y[t]
        #y0 = [observed_y[t - 1], 0] 
       # for gamma in gammas:
            
          #  y_simulated = euler_forward(gamma, k, y0, t, h)
           # y0 = [observed_y[t - 1], y_simulated[1]] 
          #  ll_value = log_likelihood(y_simulated, observed_y[t], noise_level)
           # log_likelihood_values.append(ll_value)

        # Convert to numpy array for easier plotting
       # log_likelihood_values = np.array(log_likelihood_values)

        # Plotting the log-likelihood function
       # plt.figure(figsize=(10, 6))
      #  plt.plot(gammas, log_likelihood_values, label=f'Time step {t}')
       # plt.xlabel('Gamma')
       # plt.title(f'Log-Likelihood vs. Gamma at Time step {t}')
       # plt.legend()
       # plt.grid(True)
      #  plt.show()
    
    
    p_e, p_t,Z_E,Z_T,Z_e,Z_t = find_POST_t(gamma_init,observed_y, observed_yp,noise_level, N, k, initial_conditions, T,  tol, eta_init, c1, c2, M=2)
    
    print("p_e = ",p_e)
    print("p_t = ",p_t)
    plt.figure(figsize=(10, 6))
    plt.plot(range(len(p_e)), p_e, label='p_e', marker='o', linestyle='-', color='blue')
    plt.plot(range(len(p_t)), p_t, label='p_t', marker='o', linestyle='-', color='red')
    plt.xlabel('Time Step')
    plt.ylabel('Probability')
    plt.title('Comparison of p_e and p_t Over Time Steps')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    
    


    plt.figure(figsize=(14, 8))

    plt.plot(range(len(Z_e)), Z_e, label='Z_e', marker='o', linestyle='-', color='blue', alpha=0.5)
    plt.plot(range(len(Z_E)), Z_E, label='Z_E', marker='x', linestyle='--', color='blue', alpha=0.8)
    

    plt.plot(range(len(Z_t)), Z_t, label='Z_t', marker='o', linestyle='-', color='red', alpha=0.5)
    plt.plot(range(len(Z_T)), Z_T, label='Z_T', marker='x', linestyle='--', color='red', alpha=0.8)

    for i in range(len(Z_e)):
        if Z_e[i] > Z_E[i]:
            plt.text(i, Z_e[i], 'Z_e', fontsize=9, ha='center', color='blue')
        else:
            plt.text(i, Z_E[i], 'Z_E', fontsize=9, ha='center', color='blue')

    for i in range(len(Z_t)):
        if Z_t[i] > Z_T[i]:
            plt.text(i, Z_t[i], 'Z_t', fontsize=9, ha='center', color='red')
        else:
            plt.text(i, Z_T[i], 'Z_T', fontsize=9, ha='center', color='red')

    plt.xlabel('Time Step')
    plt.ylabel('Value')
    plt.title('Comparison of Z_e, Z_E, Z_t, and Z_T Over Time Steps')
    plt.legend()
    plt.grid(True)
    plt.show()
      
    
    
    

    plt.figure(figsize=(14, 8))


    plt.plot(range(len(p_e)), p_e, label='p_e', marker='o', linestyle='-', color='blue', alpha=0.5)
    plt.plot(range(len(p_t)), p_t, label='p_t', marker='o', linestyle='-', color='red', alpha=0.5)

    plt.plot(range(len(Z_E)), Z_E, label='Z_E', marker='x', linestyle='--', color='blue', alpha=0.8)
    plt.plot(range(len(Z_T)), Z_T, label='Z_T', marker='x', linestyle='--', color='red', alpha=0.8)

    for i in range(len(p_e)):
        if (p_e[i] > p_t[i]) and (Z_E[i] > Z_T[i]):
            plt.text(i, p_e[i], 'Agree on E', fontsize=9, ha='center', color='blue')
        elif (p_t[i] > p_e[i]) and (Z_T[i] > Z_E[i]):
            plt.text(i, p_t[i], 'Agree on T', fontsize=9, ha='center', color='red')

    plt.xlabel('Time Step')
    plt.ylabel('Value')
    plt.title('Agreement of p_e/p_t with Z_E/Z_T Over Time Steps')
    plt.legend()
    plt.grid(True)
    plt.show()
